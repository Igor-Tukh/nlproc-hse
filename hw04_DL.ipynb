{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw04_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e4cd3bd39284a79a5bb5b41c7ab8226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80607d7828744491a85feb0b7f730e5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a9aa714274a4cf9aa5ba046b39f0f56",
              "IPY_MODEL_c95b9209e1c7424cb779565ab1ad320d"
            ]
          }
        },
        "80607d7828744491a85feb0b7f730e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a9aa714274a4cf9aa5ba046b39f0f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3cf263e763d540a187bd6c9555bd2cac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 49908,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49908,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_500b66080ae246618058d0455d0edeff"
          }
        },
        "c95b9209e1c7424cb779565ab1ad320d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0e5fad9e8104205b07d59a588a577fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 49908/49908 [03:00&lt;00:00, 275.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06af9cbb45fb43d2931b379da029d9fe"
          }
        },
        "3cf263e763d540a187bd6c9555bd2cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "500b66080ae246618058d0455d0edeff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0e5fad9e8104205b07d59a588a577fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06af9cbb45fb43d2931b379da029d9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c466b355cf354047bd431fc881760ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24ab68b257b24588a4c1988414e1cad1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19ebaae0e44a4ea799f48f52a5254b24",
              "IPY_MODEL_ce4b69c79fe0499799a9e422552f6c04"
            ]
          }
        },
        "24ab68b257b24588a4c1988414e1cad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19ebaae0e44a4ea799f48f52a5254b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a98666c03ae14755846380440adcb1e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86b792dcb6144e6baf360d71080494cf"
          }
        },
        "ce4b69c79fe0499799a9e422552f6c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be2db7308d104680a445d1c500a5f6e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50% 4/8 [1:10:40&lt;1:10:28, 1057.02s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1c764f223c3426dbd3b130d3bf607ed"
          }
        },
        "a98666c03ae14755846380440adcb1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86b792dcb6144e6baf360d71080494cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be2db7308d104680a445d1c500a5f6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1c764f223c3426dbd3b130d3bf607ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Igor-Tukh/nlproc-hse/blob/master/hw04_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PdocEFZ4B7x",
        "colab_type": "code",
        "outputId": "f7ecdf34-1674-4cc7-ed26-51d57c3421e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "! pip install stanfordnlp"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.17.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.10.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (42.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NCqE4Mk3vfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import stanfordnlp\n",
        "import nltk.data\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dill\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwqAIC_z31IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fX8FLx4o-K",
        "colab_type": "code",
        "outputId": "ff7cb646-e62c-4245-cdb0-4b3f50692ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "stanfordnlp.download('ru', force=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"ru_syntagrus\" for language \"ru\".\n",
            "Would you like to download the models for: ru_syntagrus now? (Y/n)\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "Downloading models for: ru_syntagrus\n",
            "Download location: /root/stanfordnlp_resources/ru_syntagrus_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 236M/236M [00:03<00:00, 58.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/ru_syntagrus_models.zip\n",
            "Extracting models file for: ru_syntagrus\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEhRhpHJ32-p",
        "colab_type": "code",
        "outputId": "50f5b81c-2891-447f-f932-3d3206a77207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIzS7iVg4WEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = 'gdrive/My Drive/nlp/'\n",
        "\n",
        "RESOURCES_PATH = 'gdrive/My Drive/nlp/resources'\n",
        "TRAIN_DATASET_PATH = os.path.join(RESOURCES_PATH, 'train_qa.csv')\n",
        "INPUT_FILE = os.path.join(RESOURCES_PATH, 'test_in.csv')\n",
        "OUTPUT_FILE = os.path.join(RESOURCES_PATH, 'output.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jn_iNJ44kHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_train_dataset():\n",
        "    data = pd.read_csv(TRAIN_DATASET_PATH) #, sep='\\t')\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfQJPB9hYdOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6836aed7-b32f-47b6-8050-5d1fd61facc1"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqvVYh_ZX8yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_sentence(text, answer):\n",
        "  ind = text.find(answer)\n",
        "  if ind == -1:\n",
        "    return None\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  cur_len = 0\n",
        "  for sentence in sentences:\n",
        "    if cur_len + len(sentence) > ind - 100:\n",
        "      word_ind = sentence.find(answer)\n",
        "      # if (answer == 'в литве') and word_ind != -1:\n",
        "      #   print(sentence, word_ind)\n",
        "      if word_ind != -1:\n",
        "        return sentence, word_ind\n",
        "    cur_len += len(sentence) + 1\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK3TyxLSYVcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ac0e0bf-fd15-43d5-c3f1-927c09917ad1"
      },
      "source": [
        "find_sentence('Привет. Мы с тобой не виделись сто лет.', 'не виделись')"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Мы с тобой не виделись сто лет.', 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37pCNv8U4rfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preapare_train_dataset():\n",
        "  data = load_train_dataset()\n",
        "  dataset = []\n",
        "  for ind, (q, a, t) in enumerate(zip(data['question'], data['answer'], data['paragraph'])):\n",
        "    a = a.lower()\n",
        "    t = t.lower()\n",
        "    q = q.lower()\n",
        "\n",
        "    if a[-3:] == '...':\n",
        "      a = a[:-3]\n",
        "    if a[-1:] == '.' or a[-1:] == '?':\n",
        "      a = a[:-1]\n",
        "    \n",
        "    answer_pos = find_sentence(t, a)\n",
        "    if answer_pos is not None:\n",
        "      q = re.split('(\\W)', q)\n",
        "      s = re.split('(\\W)', answer_pos[0])\n",
        "      dataset.append((q, (answer_pos[1], answer_pos[1] + len(a)), s, ind))\n",
        "  return np.array(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKnEVrMQV2j0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff141771-d545-4d63-ddd5-1e366f3f3cce"
      },
      "source": [
        "data = preapare_train_dataset()"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "в 1926 году в литве произошёл военный переворот, возглавивший его лидер партии таутининков (от литовского tauta — народ) антанас сметона установил авторитарный режим. 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV_AxenKV9Zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22c2f379-0993-4508-aef1-ab3d5b146527"
      },
      "source": [
        "print(f'Dataset shape is {data.shape}')"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is (49908, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tVX7oMJZ0KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_inds(t, q, stemmer, stemmed_dict):\n",
        "  seq = []\n",
        "\n",
        "  def process_words(words):\n",
        "    for word in words:\n",
        "      stemmed_word = stemmer.stem(word)\n",
        "      if stemmed_word not in stemmed_dict:\n",
        "          stemmed_dict[stemmed_word] = len(stemmed_dict)\n",
        "      seq.append(stemmed_dict[stemmed_word] + 2)\n",
        "  \n",
        "  process_words(t)\n",
        "  seq.append(0)  # sep\n",
        "  process_words(q)\n",
        "\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZAhzLEofGK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer('russian')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaNv2SftfMqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3e4cd3bd39284a79a5bb5b41c7ab8226",
            "80607d7828744491a85feb0b7f730e5d",
            "6a9aa714274a4cf9aa5ba046b39f0f56",
            "c95b9209e1c7424cb779565ab1ad320d",
            "3cf263e763d540a187bd6c9555bd2cac",
            "500b66080ae246618058d0455d0edeff",
            "e0e5fad9e8104205b07d59a588a577fa",
            "06af9cbb45fb43d2931b379da029d9fe"
          ]
        },
        "outputId": "d974e35d-8a40-4758-facf-38fe8d80d414"
      },
      "source": [
        "stemmed_dict = {}\n",
        "\n",
        "dataset = []\n",
        "for datapoint in tqdm(data):\n",
        "  dataset.append(torch.tensor(to_inds(datapoint[2], datapoint[0], stemmer, stemmed_dict)))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4cd3bd39284a79a5bb5b41c7ab8226",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=49908), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkttfKPIs1W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetp = pad_sequence(dataset, padding_value=1, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9waqRalrtG3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ys(t, a):\n",
        "  cur_len = 0\n",
        "  ys = torch.zeros(2, requires_grad=True)\n",
        "  for ind, word in enumerate(t):\n",
        "    if len(word) == 0:\n",
        "      continue\n",
        "    if cur_len == a[0]:\n",
        "      ys[0] = ind\n",
        "    if cur_len == a[1]:\n",
        "      ys[1] = (ind - 1)\n",
        "    cur_len += len(word)\n",
        "  if cur_len == a[1]:\n",
        "    ys[1] = len(t) - 1\n",
        "  # if len(ys) != 2:\n",
        "  #   cur_len = 0\n",
        "  #   print(a)\n",
        "  #   for ind, word in enumerate(t):\n",
        "  #     print(cur_len, word)\n",
        "  #     cur_len += len(word)\n",
        "  # assert len(ys) == 2\n",
        "  return ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wimpT340uOhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "\n",
        "for ind, datapoint in enumerate(data):\n",
        "  y.append(get_ys(datapoint[2], datapoint[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk5TOEVdwN6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, data_shape):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.word_embeddings = nn.Embedding(data_shape, 64)\n",
        "    self.lstm = nn.LSTM(64, 64, bidirectional=True, batch_first=True)\n",
        "    self.fc1 = nn.Linear(128, 2)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.word_embeddings(x)\n",
        "    x, _ = self.lstm(x)\n",
        "    y = self.fc1(x)\n",
        "    y = torch.transpose(y, 1, 2)\n",
        "    y = self.softmax(y)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R00EE2_v9oaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(len(stemmed_dict) + 2)\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2mO_zGhCSGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_losses(train_losses, test_losses):\n",
        "  plt.title('Losses')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  epoches = range(0, len(train_losses))\n",
        "  plt.plot(epoches, train_losses, label='train loss')\n",
        "  plt.plot(epoches, test_losses, label='test loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpVl80Mm977v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, lossf, train_batches, test_batches, epoches_number):\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "\n",
        "  for epoch in tqdm(range(epoches_number)):\n",
        "    losses = []\n",
        "    for batch in train_batches:\n",
        "      x, y = batch[0], batch[1]\n",
        "      optimizer.zero_grad()\n",
        "      output = model(x.long())\n",
        "      loss = lossf(output, y)\n",
        "      loss.backward()\n",
        "      losses.append(loss.detach().numpy())\n",
        "    train_losses.append(np.mean(np.array(losses)))\n",
        "\n",
        "    with torch.no_grad():\n",
        "      losses = []\n",
        "      for batch in test_batches:\n",
        "        x, y = batch[0], batch[1]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x.long())\n",
        "        loss = lossf(output, y)\n",
        "        losses.append(loss.detach().numpy())  \n",
        "      test_losses.append(np.mean(np.array(losses)))\n",
        "\n",
        "    if epoch % 2 == 0 or epoch == epoches_number - 1:\n",
        "      print(f'Epoch: {epoch}, train loss: {train_losses[-1]}, test loss: {test_losses[-1]}')\n",
        "\n",
        "  plot_losses(train_losses, test_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibSFHoUFzfMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_dataset = list(zip(datasetp, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5_F_aQj85H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(final_dataset, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmadlJYa9kyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bath_size = 64\n",
        "epoches_number = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "090nzMyb9M7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = torch.utils.data.DataLoader(train, batch_size=bath_size)\n",
        "test_batches = torch.utils.data.DataLoader(test, batch_size=bath_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8iRkxyFU6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_loss = nn.NLLLoss()\n",
        "\n",
        "def get_loss(output, y):\n",
        "  y0, y1 = y[:, 0].reshape(-1), y[:, 1].reshape(-1)\n",
        "  loss0 = base_loss(output[:, 0], y0.long())\n",
        "  loss1 = base_loss(output[:, 1], y1.long())\n",
        "  return loss0 + loss1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMg-xtXSAjIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "c466b355cf354047bd431fc881760ab5",
            "24ab68b257b24588a4c1988414e1cad1",
            "19ebaae0e44a4ea799f48f52a5254b24",
            "ce4b69c79fe0499799a9e422552f6c04",
            "a98666c03ae14755846380440adcb1e6",
            "86b792dcb6144e6baf360d71080494cf",
            "be2db7308d104680a445d1c500a5f6e1",
            "d1c764f223c3426dbd3b130d3bf607ed"
          ]
        },
        "outputId": "0cb58ccc-6555-48ba-a0ea-25beb061d969"
      },
      "source": [
        "train_model(model, optimizer, get_loss, train_batches, test_batches, epoches_number)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c466b355cf354047bd431fc881760ab5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, train loss: 13.255812644958496, test loss: 13.253984451293945\n",
            "Epoch: 2, train loss: 13.255812644958496, test loss: 13.253984451293945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nn48VrcGnzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_task(model):\n",
        "    with open(OUTPUT_FILE, 'w') as output_file:\n",
        "        test_data = pd.read_csv(INPUT_FILE, sep='\\t')\n",
        "        for quid, pid, q, p in tqdm(zip(test_data['question_id'], test_data['paragraph_id'], test_data['question'], test_data['paragraph'])):\n",
        "            candidates, rq, rs, s = generate_candidates(p, q)\n",
        "            X_test = [build_features(p, q, c, rq=rq, rs=rs, candidate_sentence=s) for c in candidates]\n",
        "            X_test = discretaze_X(X_test, train=False)\n",
        "            y_test = model.predict(X_test)\n",
        "            y_max = None\n",
        "            ans = None\n",
        "            for ind in range(len(candidates)):\n",
        "                if y_max is None or y_test[ind] > y_max:\n",
        "                    y_max = y_test[ind]\n",
        "                    ans = candidates[ind]\n",
        "            output_file.write(f'{quid}\\t{ans}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}